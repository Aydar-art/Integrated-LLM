"""
–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Ollama API.
"""
import requests
import json
import time
from typing import Dict, Any, Generator
import config
import utils

class OllamaClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å Ollama API."""
    
    def __init__(self, model: str = "llama3.1:8b"):
        self.model = model
        self.url = config.OLLAMA_URL
        self.stream_url = config.OLLAMA_STREAM_URL
        self.session = requests.Session()
        self.system_prompt = config.SYSTEM_PROMPT
    
    def send_request(self, prompt: str, conversation_history: list = None) -> str:
        """
        –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Ollama API.
        """
        # –ï—Å–ª–∏ streaming –≤—ã–∫–ª—é—á–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –º–µ—Ç–æ–¥
        if not config.STREAMING_ENABLED:
            return self._send_standard_request(prompt, conversation_history)
        
        # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º streaming
        return self._send_streaming_request(prompt, conversation_history)
    
    def _send_standard_request(self, prompt: str, conversation_history: list = None) -> str:
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ streaming."""
        full_prompt = self._build_prompt(prompt, conversation_history)
        
        payload = {
            "model": self.model,
            "prompt": full_prompt,
            "stream": False,
            "options": {
                "temperature": 0.3,
                "top_p": 0.9,
                "num_predict": 4096,
                "repeat_penalty": 1.1
            }
        }
        
        try:
            response = self.session.post(self.url, json=payload, timeout=config.TIMEOUT_SECONDS)
            response.raise_for_status()
            
            result = response.json()
            ai_response = result.get("response", "–û—à–∏–±–∫–∞: –æ—Ç–≤–µ—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω")
            
            return ai_response
            
        except requests.exceptions.ConnectionError:
            return "‚ùå –û—à–∏–±–∫–∞: Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: `ollama serve`"
        except requests.exceptions.Timeout:
            return "‚è∞ –û—à–∏–±–∫–∞: –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –∏—Å—Ç–µ–∫–ª–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–ø—Ä–æ—Å—Ç–∏—Ç—å –∑–∞–ø—Ä–æ—Å."
        except requests.exceptions.HTTPError as e:
            return f"üåê –û—à–∏–±–∫–∞ HTTP: {str(e)}"
        except json.JSONDecodeError:
            return "‚ùå –û—à–∏–±–∫–∞: –Ω–µ–≤–µ—Ä–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞ Ollama"
        except Exception as e:
            return f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
    
    def _send_streaming_request(self, prompt: str, conversation_history: list = None) -> str:
        """Streaming –∑–∞–ø—Ä–æ—Å —Å –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω—ã–º –≤—ã–≤–æ–¥–æ–º."""
        full_prompt = self._build_prompt(prompt, conversation_history)
        
        payload = {
            "model": self.model,
            "prompt": full_prompt,
            "stream": True,  # –í–∫–ª—é—á–∞–µ–º streaming
            "options": {
                "temperature": 0.3,
                "top_p": 0.9,
                "num_predict": 4096,
                "repeat_penalty": 1.1
            }
        }
        
        try:
            utils.print_colored("ü§ñ AI:", "green")
            print("", end="", flush=True)  # –ù–∞—á–∞–ª–æ –æ—Ç–≤–µ—Ç–∞
            
            full_response = ""
            line_buffer = ""
            
            response = self.session.post(self.stream_url, json=payload, timeout=config.TIMEOUT_SECONDS, stream=True)
            response.raise_for_status()
            
            for line in response.iter_lines():
                if line:
                    try:
                        # –ü–∞—Ä—Å–∏–º JSON –∏–∑ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
                        data = json.loads(line.decode('utf-8'))
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —á–∞—Å—Ç—å –æ—Ç–≤–µ—Ç–∞
                        if 'response' in data:
                            chunk = data['response']
                            full_response += chunk
                            line_buffer += chunk
                            
                            # –í—ã–≤–æ–¥–∏–º –ø–æ —Å–∏–º–≤–æ–ª–∞–º –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
                            for char in chunk:
                                print(char, end='', flush=True)
                                time.sleep(config.STREAM_DELAY)
                            
                            # –ï—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª–∞—Å—å —Ü–µ–ª–∞—è —Å—Ç—Ä–æ–∫–∞, –≤—ã–≤–æ–¥–∏–º –ø–µ—Ä–µ–≤–æ–¥ —Å—Ç—Ä–æ–∫–∏
                            if '\n' in line_buffer:
                                line_buffer = ""
                        
                        # –ï—Å–ª–∏ —ç—Ç–æ –∫–æ–Ω–µ—Ü –æ—Ç–≤–µ—Ç–∞
                        if data.get('done', False):
                            print()  # –ó–∞–≤–µ—Ä—à–∞–µ–º —Å—Ç—Ä–æ–∫—É
                            break
                            
                    except json.JSONDecodeError:
                        continue
                    except Exception as e:
                        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ streaming: {str(e)}")
                        break
            
            return full_response
            
        except requests.exceptions.ConnectionError:
            return "‚ùå –û—à–∏–±–∫–∞: Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: `ollama serve`"
        except requests.exceptions.Timeout:
            return "‚è∞ –û—à–∏–±–∫–∞: –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –∏—Å—Ç–µ–∫–ª–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–ø—Ä–æ—Å—Ç–∏—Ç—å –∑–∞–ø—Ä–æ—Å."
        except requests.exceptions.HTTPError as e:
            return f"üåê –û—à–∏–±–∫–∞ HTTP: {str(e)}"
        except Exception as e:
            return f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
    
    def _build_prompt(self, prompt: str, conversation_history: list = None) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º."""
        context = ""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if conversation_history:
            context += "–ü—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è:\n"
            for chat in conversation_history[-3:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è
                context += f"User: {chat['user']}\nAI: {chat['ai'][:100]}...\n"
        
        return f"{self.system_prompt}\n\n{context}\n\n–ó–∞–ø—Ä–æ—Å: {prompt}"
    
    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Å—Å–∏–∏."""
        self.session.close()
