"""
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤.
"""
import os
import requests
import json
import time
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional
import config
import utils

class LLMProvider(ABC):
    """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –∫–ª–∞—Å—Å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ LLM."""
    
    @abstractmethod
    def send_request(self, prompt: str, **kwargs) -> str:
        pass
    
    @abstractmethod
    def get_available_models(self) -> List[str]:
        pass

class OllamaProvider(LLMProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è Ollama."""
    
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.session = requests.Session()
    
    def send_request(self, prompt: str, model: str = "llama3.1:8b", 
                    temperature: float = 0.3, stream: bool = True, **kwargs) -> str:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Ollama."""
        url = f"{self.base_url}/api/generate"
        
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": stream,
            "options": {
                "temperature": temperature,
                "top_p": 0.9,
                "num_predict": 8192,
                "repeat_penalty": 1.1
            }
        }
        
        try:
            if stream:
                return self._stream_request(url, payload)
            else:
                return self._standard_request(url, payload)
                
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ Ollama: {str(e)}"
    
    def _standard_request(self, url: str, payload: dict) -> str:
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ streaming."""
        response = self.session.post(url, json=payload, timeout=config.TIMEOUT_SECONDS)
        response.raise_for_status()
        result = response.json()
        return result.get("response", "–û—à–∏–±–∫–∞: –æ—Ç–≤–µ—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω")
    
    def _stream_request(self, url: str, payload: dict) -> str:
        """Streaming –∑–∞–ø—Ä–æ—Å."""
        utils.print_colored("ü§ñ AI:", "green")
        print("", end="", flush=True)
        
        full_response = ""
        response = self.session.post(url, json=payload, timeout=config.TIMEOUT_SECONDS, stream=True)
        response.raise_for_status()
        
        for line in response.iter_lines():
            if line:
                try:
                    data = json.loads(line.decode('utf-8'))
                    if 'response' in data:
                        chunk = data['response']
                        full_response += chunk
                        print(chunk, end='', flush=True)
                        time.sleep(config.STREAM_DELAY)
                    
                    if data.get('done', False):
                        print()
                        break
                except:
                    continue
        
        return full_response
    
    def get_available_models(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Ollama."""
        try:
            response = self.session.get(f"{self.base_url}/api/tags", timeout=10)
            if response.status_code == 200:
                models = response.json().get('models', [])
                return [model['name'] for model in models]
        except:
            pass
        return []

class OpenAIClient(LLMProvider):
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è OpenAI API."""
    
    def __init__(self, api_key: str = None, base_url: str = "https://api.openai.com/v1"):
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        self.base_url = base_url.rstrip('/')
        self.session = requests.Session()
        if self.api_key:
            self.session.headers.update({
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            })
    
    def send_request(self, prompt: str, model: str = "gpt-3.5-turbo", 
                    temperature: float = 0.3, stream: bool = True, **kwargs) -> str:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI."""
        if not self.api_key:
            return "‚ùå OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: !set openai <api_key>"
        
        url = f"{self.base_url}/chat/completions"
        
        messages = [{"role": "user", "content": prompt}]
        
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "stream": stream
        }
        
        try:
            if stream:
                return self._stream_request(url, payload)
            else:
                return self._standard_request(url, payload)
                
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ OpenAI: {str(e)}"
    
    def _standard_request(self, url: str, payload: dict) -> str:
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å."""
        response = self.session.post(url, json=payload, timeout=config.TIMEOUT_SECONDS)
        response.raise_for_status()
        result = response.json()
        return result['choices'][0]['message']['content']
    
    def _stream_request(self, url: str, payload: dict) -> str:
        """Streaming –∑–∞–ø—Ä–æ—Å."""
        utils.print_colored("ü§ñ AI:", "green")
        print("", end="", flush=True)
        
        full_response = ""
        response = self.session.post(url, json=payload, timeout=config.TIMEOUT_SECONDS, stream=True)
        response.raise_for_status()
        
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    if line.strip() == 'data: [DONE]':
                        print()
                        break
                    
                    try:
                        data = json.loads(line[6:])
                        if 'choices' in data and len(data['choices']) > 0:
                            delta = data['choices'][0].get('delta', {})
                            if 'content' in delta:
                                chunk = delta['content']
                                full_response += chunk
                                print(chunk, end='', flush=True)
                                time.sleep(config.STREAM_DELAY)
                    except:
                        continue
        
        return full_response
    
    def get_available_models(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π OpenAI."""
        if not self.api_key:
            return []
        
        try:
            response = self.session.get(f"{self.base_url}/models", timeout=10)
            if response.status_code == 200:
                models = response.json().get('data', [])
                return [model['id'] for model in models if model['id'].startswith('gpt')]
        except:
            pass
        return []

class DeepSeekClient(LLMProvider):
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è DeepSeek API."""
    
    def __init__(self, api_key: str = None, base_url: str = "https://api.deepseek.com/v1"):
        self.api_key = api_key or os.getenv('DEEPSEEK_API_KEY')
        self.base_url = base_url.rstrip('/')
        self.session = requests.Session()
        if self.api_key:
            self.session.headers.update({
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            })
    
    def send_request(self, prompt: str, model: str = "deepseek-chat", 
                    temperature: float = 0.3, stream: bool = True, **kwargs) -> str:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ DeepSeek."""
        if not self.api_key:
            return "‚ùå DeepSeek API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: !set deepseek <api_key>"
        
        url = f"{self.base_url}/chat/completions"
        
        messages = [{"role": "user", "content": prompt}]
        
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "stream": stream
        }
        
        try:
            if stream:
                return self._stream_request(url, payload)
            else:
                return self._standard_request(url, payload)
                
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ DeepSeek: {str(e)}"
    
    def _standard_request(self, url: str, payload: dict) -> str:
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å."""
        response = self.session.post(url, json=payload, timeout=config.TIMEOUT_SECONDS)
        response.raise_for_status()
        result = response.json()
        return result['choices'][0]['message']['content']
    
    def _stream_request(self, url: str, payload: dict) -> str:
        """Streaming –∑–∞–ø—Ä–æ—Å."""
        utils.print_colored("ü§ñ AI:", "green")
        print("", end="", flush=True)
        
        full_response = ""
        response = self.session.post(url, json=payload, timeout=config.TIMEOUT_SECONDS, stream=True)
        response.raise_for_status()
        
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    if line.strip() == 'data: [DONE]':
                        print()
                        break
                    
                    try:
                        data = json.loads(line[6:])
                        if 'choices' in data and len(data['choices']) > 0:
                            delta = data['choices'][0].get('delta', {})
                            if 'content' in delta:
                                chunk = delta['content']
                                full_response += chunk
                                print(chunk, end='', flush=True)
                                time.sleep(config.STREAM_DELAY)
                    except:
                        continue
        
        return full_response
    
    def get_available_models(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π DeepSeek."""
        if not self.api_key:
            return []
        
        # DeepSeek –æ–±—ã—á–Ω–æ –∏–º–µ–µ—Ç —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –º–æ–¥–µ–ª–µ–π
        return ["deepseek-chat", "deepseek-coder"]

class ProviderManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏."""
    
    def __init__(self):
        self.providers = {
            "ollama": OllamaProvider(),
            "openai": OpenAIClient(),
            "deepseek": DeepSeekClient()
        }
        self.current_provider = "ollama"
        self.current_model = "llama3.1:8b"
    
    def set_provider(self, provider_name: str) -> bool:
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞."""
        if provider_name in self.providers:
            self.current_provider = provider_name
            return True
        return False
    
    def set_model(self, model_name: str) -> bool:
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏."""
        self.current_model = model_name
        return True
    
    def set_api_key(self, provider_name: str, api_key: str) -> bool:
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ API –∫–ª—é—á–∞ –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞."""
        if provider_name == "openai":
            self.providers["openai"] = OpenAIClient(api_key)
            return True
        elif provider_name == "deepseek":
            self.providers["deepseek"] = DeepSeekClient(api_key)
            return True
        return False
    
    def send_request(self, prompt: str, **kwargs) -> str:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä."""
        provider = self.providers[self.current_provider]
        model = kwargs.get('model', self.current_model)
        
        return provider.send_request(
            prompt=prompt,
            model=model,
            temperature=kwargs.get('temperature', 0.3),
            stream=kwargs.get('stream', True)
        )
    
    def get_available_providers(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤."""
        return list(self.providers.keys())
    
    def get_available_models(self, provider_name: str = None) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞."""
        provider_name = provider_name or self.current_provider
        if provider_name in self.providers:
            return self.providers[provider_name].get_available_models()
        return []
    
    def test_connection(self, provider_name: str = None) -> str:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º."""
        provider_name = provider_name or self.current_provider
        if provider_name in self.providers:
            models = self.get_available_models(provider_name)
            if models:
                return f"‚úÖ {provider_name} –¥–æ—Å—Ç—É–ø–µ–Ω. –ú–æ–¥–µ–ª–∏: {', '.join(models[:5])}"
            else:
                return f"‚ùå {provider_name} –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –Ω–µ—Ç –º–æ–¥–µ–ª–µ–π"
        return f"‚ùå –ü—Ä–æ–≤–∞–π–¥–µ—Ä {provider_name} –Ω–µ –Ω–∞–π–¥–µ–Ω"
